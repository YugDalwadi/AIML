{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "fullTrainSet = pd.read_csv(r\"C:\\Users\\yug\\Desktop\\Projects\\AIML\\Titanic Spaceship\\cleanedUpTrain.csv\")\n",
    "\n",
    "xSet = fullTrainSet.iloc[:, :9].copy()\n",
    "xSet = xSet.drop([\"PassengerId\", \"Cabin\", \"Name\"], axis=1)\n",
    "ySet = fullTrainSet.iloc[:, 9].copy()\n",
    "ySet = LabelBinarizer().fit_transform(ySet)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xSet,ySet, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalExpenditure   -0.197107\n",
      "Age                -0.074233\n",
      "VIP                -0.037261\n",
      "CryoSleep           0.458258\n",
      "Transported         1.000000\n",
      "Name: Transported, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corrMatrix = fullTrainSet.corr()\n",
    "print(corrMatrix[\"Transported\"].sort_values(ascending=True))\n",
    "# For now I'll keep all features, but reminder to check heatmap using Random Forests and go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a custom encoder that can encode multiple columns at once\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "classIndices = [\"HomePlanet\",\"CryoSleep\",\"VIP\",\"Destination\"]\n",
    "class MultiClassEncoder:\n",
    "    def __init__(self, classIndices=None):\n",
    "        self.classIndices = classIndices\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        xCopy = X.copy()\n",
    "        for Indice in self.classIndices:\n",
    "            xCopy.loc[:, Indice] = LabelEncoder.fit_transform(LabelEncoder, y=xCopy.loc[:, Indice])\n",
    "        return xCopy\n",
    "    \n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "labelPipeline = Pipeline([\n",
    "    (\"LabelEncoder\", MultiClassEncoder(classIndices)),\n",
    "])\n",
    "numPipeline = Pipeline([\n",
    "    (\"stdScaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "prepxTrain = labelPipeline.fit_transform(xTrain)\n",
    "prepxTrain = numPipeline.fit_transform(prepxTrain)\n",
    "prepyTrain = np.ravel(yTrain)\n",
    "\n",
    "prepxTest = labelPipeline.fit_transform(xTest)\n",
    "prepxTest = numPipeline.fit_transform(prepxTest)\n",
    "prepyTest = np.ravel(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461256967212962\n",
      "0.8007328443254957\n",
      "0.8461256967212962\n",
      "0.8468050430344449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ridgeClf = RidgeClassifier(alpha=0.1)\n",
    "ridgeClf.fit(prepxTrain,prepyTrain)\n",
    "yPredRidge = ridgeClf.predict(prepxTest)\n",
    "print(np.sqrt(accuracy_score(yTest,yPredRidge)))\n",
    "\n",
    "decTreeClf = DecisionTreeClassifier()\n",
    "decTreeClf.fit(prepxTrain,prepyTrain)\n",
    "yPredTree = decTreeClf.predict(prepxTest)\n",
    "print(np.sqrt(accuracy_score(yTest,yPredTree)))\n",
    "\n",
    "SVCClf = LinearSVC(C=0.001)\n",
    "SVCClf.fit(prepxTrain,prepyTrain)\n",
    "yPredSVC = SVCClf.predict(prepxTest)\n",
    "print(np.sqrt(accuracy_score(yTest,yPredSVC)))\n",
    "\n",
    "logReg = LogisticRegression(C=50)\n",
    "logReg.fit(prepxTrain,prepyTrain)\n",
    "yPredLogReg = logReg.predict(prepxTest)\n",
    "print(np.sqrt(accuracy_score(yTest,yPredLogReg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Param Grid searching for a promising model for Logistic Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "myGrid = GridSearchCV(estimator=logReg ,param_grid={\"C\":[1,10,50,0.1,0.001,0.5], \"solver\": [\"lbfgs\", \"liblinear\"]})\n",
    "myGrid.fit(prepxTrain,prepyTrain)\n",
    "myGrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6647498562392179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFCClf = RandomForestClassifier(bootstrap=False)\n",
    "\n",
    "class ClassifierEarlyStopping():\n",
    "    def __init__(self, estimator, nEstimators):\n",
    "        self.estimator = estimator\n",
    "        self.nEstimators = nEstimators\n",
    "    def estimatorFit(self):\n",
    "        estimator = clone(self.estimator)\n",
    "        estimator.n_estimators = 1\n",
    "        estimator.warm_start = True\n",
    "        return estimator\n",
    "        \n",
    "    def earlyStopping(self,X,y, xVal, yVal):\n",
    "        est = self.estimatorFit()\n",
    "        est.n_estimators = self.nEstimators\n",
    "\n",
    "        errors= []\n",
    "        for nEst in range(1, est.n_estimators+1):\n",
    "            est.n_estimators = nEst\n",
    "            est.fit(X,y)\n",
    "            yPred = est.predict(xVal)\n",
    "            errors.append(accuracy_score(yVal, yPred))\n",
    "        bestError = np.amax(errors)\n",
    "        return bestError\n",
    "\n",
    "ae = ClassifierEarlyStopping(RFCClf, 200).earlyStopping(prepxTrain,prepyTrain, prepxTest,prepyTest)\n",
    "print(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.8542421961772491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBReg = GradientBoostingClassifier(learning_rate=0.5, n_estimators=250, warm_start=True)\n",
    "GBReg.fit(prepxTrain,prepyTrain)\n",
    "errors = []\n",
    "for yPred in GBReg.staged_predict(prepxTest):\n",
    "    errors = errors + [np.sqrt(accuracy_score(prepyTest, yPred))]\n",
    "bestModel = np.argmax(errors) + 1\n",
    "print(bestModel)\n",
    "bestGBRReg = GradientBoostingClassifier(learning_rate=0.5, n_estimators=bestModel)\n",
    "bestGBRReg.fit(prepxTrain,prepyTrain)\n",
    "yPredGBR = bestGBRReg.predict(prepxTest)\n",
    "print(np.sqrt(accuracy_score(prepyTest, yPredGBR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model seems to be a GradientBoostingRegressor so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "fullTestSet = pd.read_csv(r\"C:\\Users\\yug\\Desktop\\Projects\\AIML\\Titanic Spaceship\\cleanedUpTest.csv\")\n",
    "fullTestSet = fullTestSet.iloc[:, :13].copy()\n",
    "passengerID = fullTestSet.iloc[:, 0].copy()\n",
    "fullTestSet = fullTestSet.drop([\"PassengerId\", \"Cabin\", \"Name\"], axis=1)\n",
    "prepTestSet = labelPipeline.fit_transform(fullTestSet)\n",
    "prepTestSet = numPipeline.fit_transform(prepTestSet)\n",
    "finalPreds = bestGBRReg.predict(prepTestSet)\n",
    "print(finalPreds)\n",
    "finalPreds = finalPreds.tolist()\n",
    "\n",
    "for i in range(len(finalPreds)):\n",
    "    if(finalPreds[i] == 1):\n",
    "        finalPreds[i] = True\n",
    "    elif(finalPreds[i] == 0):\n",
    "        finalPreds[i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = pd.DataFrame()\n",
    "finalData[\"PassengerId\"] = passengerID\n",
    "finalData[\"Transported\"] = pd.DataFrame(finalPreds)\n",
    "finalData.to_csv(r\"C:\\Users\\yug\\Desktop\\Projects\\AIML\\Titanic Spaceship\\finalPreds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
